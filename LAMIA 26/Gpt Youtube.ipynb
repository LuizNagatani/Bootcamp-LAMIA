{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-","timestamp":1723857867265}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5hjCcLDr2WC","executionInfo":{"status":"ok","timestamp":1723858674917,"user_tz":180,"elapsed":905,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"0dfb95a2-7102-4d7b-e2b3-c17a45c6656f"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-08-17 01:37:54--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘input.txt’\n","\n","\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n","\n","2024-08-17 01:37:54 (18.8 MB/s) - ‘input.txt’ saved [1115394/1115394]\n","\n"]}],"source":["\n","!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"]},{"cell_type":"code","source":["\n","with open('itenstboi.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()"],"metadata":{"id":"O6medjfRsLD9","executionInfo":{"status":"ok","timestamp":1723862809318,"user_tz":180,"elapsed":311,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["print(\"length of dataset in characters: \", len(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xWI_VyAsN8F","executionInfo":{"status":"ok","timestamp":1723862810544,"user_tz":180,"elapsed":4,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"831760dc-23e3-43ed-f761-7c02322b6864"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["length of dataset in characters:  7590\n"]}]},{"cell_type":"code","source":["\n","print(text[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c5V0FvqseE0","executionInfo":{"status":"ok","timestamp":1723862814734,"user_tz":180,"elapsed":281,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"551daac8-5038-4907-e9ea-01232db8dc66"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["1up!: Grants an extra life.,\n","    3 Dollar Bill: Tears have random effects.,\n","    9 Volt: Quicker charge for item usage.,\n","    A Lump of Coal: Damage increases the further your tears travel.,\n","    A Quarter: Grants 25 coins.,\n","    Abaddon: Increases damage, removes red hearts, adds black hearts.,\n","    The Battery: Increases charge speed for items.,\n","    The Bean: Releases a toxic gas when used.,\n","    The Book of Belial: Increases damage for the current room.,\n","    The Book of Shadows: Grants temporary invincibility.,\n","    The D6: Allows re-rolling of item pedestals.,\n","    The D20: Rerolls all pickups into new pickups.,\n","    The D4: Rerolls all of Isaac's items.,\n","    The Guppy's Head: Releases flies when used.,\n","    The Halo: Increases all stats.,\n","    The Nail: Grants invincibility and boosts damage.,\n","    The Polaroid: Grants a shield when at half a heart or less.,\n","    The Pact: Increases damage and tears rate.,\n","    The Relic: Drops a soul heart every few rooms.,\n","    The Sacred Heart: Significantly \n"]}]},{"cell_type":"code","source":["\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print(vocab_size) #todos os caracteres presentes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0e-Rbyr8sfM8","executionInfo":{"status":"ok","timestamp":1723862819389,"user_tz":180,"elapsed":297,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"f13704c8-e6d5-425a-ebd3-08cf1496681f"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !',-.0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","70\n"]}]},{"cell_type":"code","source":["\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s]\n","decode = lambda l: ''.join([itos[i] for i in l]) # tokenização básica\n","\n","print(encode(\"hii there\"))\n","print(decode(encode(\"hii there\")))\n","print(decode([46])) #a tokenização é realizada por letra aqui, diferente do card 22"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yw1LKNCgwjj1","executionInfo":{"status":"ok","timestamp":1723862821395,"user_tz":180,"elapsed":275,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"14efdffc-d7b0-49d7-b47a-e8c889686677"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["[51, 52, 52, 1, 63, 51, 48, 61, 48]\n","hii there\n","c\n"]}]},{"cell_type":"code","source":["\n","import torch\n","data = torch.tensor(encode(text), dtype=torch.long)\n","print(data.shape, data.dtype)\n","print(data[:1000]) # o dataset foi tokenizado e armazenado dentro de um tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJb0OXPwzvqg","executionInfo":{"status":"ok","timestamp":1723862833593,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"e98d439e-a588-4c1c-8a7a-adc7ebf0d133"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([7590]) torch.int64\n","tensor([ 8, 64, 59,  2, 17,  1, 24, 61, 44, 57, 63, 62,  1, 44, 57,  1, 48, 67,\n","        63, 61, 44,  1, 55, 52, 49, 48,  6,  4,  0,  1,  1,  1,  1, 10,  1, 21,\n","        58, 55, 55, 44, 61,  1, 19, 52, 55, 55, 17,  1, 37, 48, 44, 61, 62,  1,\n","        51, 44, 65, 48,  1, 61, 44, 57, 47, 58, 56,  1, 48, 49, 49, 48, 46, 63,\n","        62,  6,  4,  0,  1,  1,  1,  1, 16,  1, 39, 58, 55, 63, 17,  1, 34, 64,\n","        52, 46, 54, 48, 61,  1, 46, 51, 44, 61, 50, 48,  1, 49, 58, 61,  1, 52,\n","        63, 48, 56,  1, 64, 62, 44, 50, 48,  6,  4,  0,  1,  1,  1,  1, 18,  1,\n","        29, 64, 56, 59,  1, 58, 49,  1, 20, 58, 44, 55, 17,  1, 21, 44, 56, 44,\n","        50, 48,  1, 52, 57, 46, 61, 48, 44, 62, 48, 62,  1, 63, 51, 48,  1, 49,\n","        64, 61, 63, 51, 48, 61,  1, 68, 58, 64, 61,  1, 63, 48, 44, 61, 62,  1,\n","        63, 61, 44, 65, 48, 55,  6,  4,  0,  1,  1,  1,  1, 18,  1, 34, 64, 44,\n","        61, 63, 48, 61, 17,  1, 24, 61, 44, 57, 63, 62,  1,  9, 12,  1, 46, 58,\n","        52, 57, 62,  6,  4,  0,  1,  1,  1,  1, 18, 45, 44, 47, 47, 58, 57, 17,\n","         1, 26, 57, 46, 61, 48, 44, 62, 48, 62,  1, 47, 44, 56, 44, 50, 48,  4,\n","         1, 61, 48, 56, 58, 65, 48, 62,  1, 61, 48, 47,  1, 51, 48, 44, 61, 63,\n","        62,  4,  1, 44, 47, 47, 62,  1, 45, 55, 44, 46, 54,  1, 51, 48, 44, 61,\n","        63, 62,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 19, 44, 63, 63, 48,\n","        61, 68, 17,  1, 26, 57, 46, 61, 48, 44, 62, 48, 62,  1, 46, 51, 44, 61,\n","        50, 48,  1, 62, 59, 48, 48, 47,  1, 49, 58, 61,  1, 52, 63, 48, 56, 62,\n","         6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 19, 48, 44, 57, 17,  1, 35,\n","        48, 55, 48, 44, 62, 48, 62,  1, 44,  1, 63, 58, 67, 52, 46,  1, 50, 44,\n","        62,  1, 66, 51, 48, 57,  1, 64, 62, 48, 47,  6,  4,  0,  1,  1,  1,  1,\n","        37, 51, 48,  1, 19, 58, 58, 54,  1, 58, 49,  1, 19, 48, 55, 52, 44, 55,\n","        17,  1, 26, 57, 46, 61, 48, 44, 62, 48, 62,  1, 47, 44, 56, 44, 50, 48,\n","         1, 49, 58, 61,  1, 63, 51, 48,  1, 46, 64, 61, 61, 48, 57, 63,  1, 61,\n","        58, 58, 56,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 19, 58, 58, 54,\n","         1, 58, 49,  1, 36, 51, 44, 47, 58, 66, 62, 17,  1, 24, 61, 44, 57, 63,\n","        62,  1, 63, 48, 56, 59, 58, 61, 44, 61, 68,  1, 52, 57, 65, 52, 57, 46,\n","        52, 45, 52, 55, 52, 63, 68,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1,\n","        21, 13, 17,  1, 18, 55, 55, 58, 66, 62,  1, 61, 48,  5, 61, 58, 55, 55,\n","        52, 57, 50,  1, 58, 49,  1, 52, 63, 48, 56,  1, 59, 48, 47, 48, 62, 63,\n","        44, 55, 62,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 21,  9,  7, 17,\n","         1, 35, 48, 61, 58, 55, 55, 62,  1, 44, 55, 55,  1, 59, 52, 46, 54, 64,\n","        59, 62,  1, 52, 57, 63, 58,  1, 57, 48, 66,  1, 59, 52, 46, 54, 64, 59,\n","        62,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 21, 11, 17,  1, 35, 48,\n","        61, 58, 55, 55, 62,  1, 44, 55, 55,  1, 58, 49,  1, 26, 62, 44, 44, 46,\n","         3, 62,  1, 52, 63, 48, 56, 62,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,\n","         1, 24, 64, 59, 59, 68,  3, 62,  1, 25, 48, 44, 47, 17,  1, 35, 48, 55,\n","        48, 44, 62, 48, 62,  1, 49, 55, 52, 48, 62,  1, 66, 51, 48, 57,  1, 64,\n","        62, 48, 47,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 25, 44, 55, 58,\n","        17,  1, 26, 57, 46, 61, 48, 44, 62, 48, 62,  1, 44, 55, 55,  1, 62, 63,\n","        44, 63, 62,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 31, 44, 52, 55,\n","        17,  1, 24, 61, 44, 57, 63, 62,  1, 52, 57, 65, 52, 57, 46, 52, 45, 52,\n","        55, 52, 63, 68,  1, 44, 57, 47,  1, 45, 58, 58, 62, 63, 62,  1, 47, 44,\n","        56, 44, 50, 48,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1, 33, 58, 55,\n","        44, 61, 58, 52, 47, 17,  1, 24, 61, 44, 57, 63, 62,  1, 44,  1, 62, 51,\n","        52, 48, 55, 47,  1, 66, 51, 48, 57,  1, 44, 63,  1, 51, 44, 55, 49,  1,\n","        44,  1, 51, 48, 44, 61, 63,  1, 58, 61,  1, 55, 48, 62, 62,  6,  4,  0,\n","         1,  1,  1,  1, 37, 51, 48,  1, 33, 44, 46, 63, 17,  1, 26, 57, 46, 61,\n","        48, 44, 62, 48, 62,  1, 47, 44, 56, 44, 50, 48,  1, 44, 57, 47,  1, 63,\n","        48, 44, 61, 62,  1, 61, 44, 63, 48,  6,  4,  0,  1,  1,  1,  1, 37, 51,\n","        48,  1, 35, 48, 55, 52, 46, 17,  1, 21, 61, 58, 59, 62,  1, 44,  1, 62,\n","        58, 64, 55,  1, 51, 48, 44, 61, 63,  1, 48, 65, 48, 61, 68,  1, 49, 48,\n","        66,  1, 61, 58, 58, 56, 62,  6,  4,  0,  1,  1,  1,  1, 37, 51, 48,  1,\n","        36, 44, 46, 61, 48, 47,  1, 25, 48, 44, 61, 63, 17,  1, 36, 52, 50, 57,\n","        52, 49, 52, 46, 44, 57, 63, 55, 68,  1])\n"]}]},{"cell_type":"code","source":["n = int(0.9*len(data)) # efetuando train/test split\n","train_data = data[:n]\n","val_data = data[n:]"],"metadata":{"id":"f_WIXqxz0lU5","executionInfo":{"status":"ok","timestamp":1723862839080,"user_tz":180,"elapsed":284,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["block_size = 8\n","train_data[:block_size+1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TD5Bj8Y6IAD4","executionInfo":{"status":"ok","timestamp":1723862840189,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"62ce35ec-b026-4da0-b048-2d27bdd43914"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 8, 64, 59,  2, 17,  1, 24, 61, 44])"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","    context = x[:t+1]\n","    target = y[t]\n","    print(f\"when input is {context} the target: {target}\") #exemplifica o processo de treinamento para o modelo realizar predições do caractére seguinte"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HXDe8vGJCEn","executionInfo":{"status":"ok","timestamp":1723862841773,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"d95c356d-693f-4744-8980-50b949242cee"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["when input is tensor([8]) the target: 64\n","when input is tensor([ 8, 64]) the target: 59\n","when input is tensor([ 8, 64, 59]) the target: 2\n","when input is tensor([ 8, 64, 59,  2]) the target: 17\n","when input is tensor([ 8, 64, 59,  2, 17]) the target: 1\n","when input is tensor([ 8, 64, 59,  2, 17,  1]) the target: 24\n","when input is tensor([ 8, 64, 59,  2, 17,  1, 24]) the target: 61\n","when input is tensor([ 8, 64, 59,  2, 17,  1, 24, 61]) the target: 44\n"]}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size = 4\n","block_size = 8\n","\n","def get_batch(split):\n","\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    return x, y\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","\n","print('----')\n","\n","for b in range(batch_size):\n","    for t in range(block_size):\n","        context = xb[b, :t+1]\n","        target = yb[b,t]\n","        print(f\"when input is {context.tolist()} the target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3k1Czf7LuA9","executionInfo":{"status":"ok","timestamp":1723862845913,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"b19bfe12-3a36-4b6d-d9ab-ade3dd97db66"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([4, 8])\n","tensor([[ 1,  1,  1, 20, 51, 44, 61, 56],\n","        [63, 51,  1, 56, 58, 61, 48,  1],\n","        [45, 44, 55, 55,  6,  4,  0,  1],\n","        [56, 44, 50, 48,  1, 58, 49,  1]])\n","targets:\n","torch.Size([4, 8])\n","tensor([[ 1,  1, 20, 51, 44, 61, 56, 48],\n","        [51,  1, 56, 58, 61, 48,  1, 47],\n","        [44, 55, 55,  6,  4,  0,  1,  1],\n","        [44, 50, 48,  1, 58, 49,  1, 63]])\n","----\n","when input is [1] the target: 1\n","when input is [1, 1] the target: 1\n","when input is [1, 1, 1] the target: 20\n","when input is [1, 1, 1, 20] the target: 51\n","when input is [1, 1, 1, 20, 51] the target: 44\n","when input is [1, 1, 1, 20, 51, 44] the target: 61\n","when input is [1, 1, 1, 20, 51, 44, 61] the target: 56\n","when input is [1, 1, 1, 20, 51, 44, 61, 56] the target: 48\n","when input is [63] the target: 51\n","when input is [63, 51] the target: 1\n","when input is [63, 51, 1] the target: 56\n","when input is [63, 51, 1, 56] the target: 58\n","when input is [63, 51, 1, 56, 58] the target: 61\n","when input is [63, 51, 1, 56, 58, 61] the target: 48\n","when input is [63, 51, 1, 56, 58, 61, 48] the target: 1\n","when input is [63, 51, 1, 56, 58, 61, 48, 1] the target: 47\n","when input is [45] the target: 44\n","when input is [45, 44] the target: 55\n","when input is [45, 44, 55] the target: 55\n","when input is [45, 44, 55, 55] the target: 6\n","when input is [45, 44, 55, 55, 6] the target: 4\n","when input is [45, 44, 55, 55, 6, 4] the target: 0\n","when input is [45, 44, 55, 55, 6, 4, 0] the target: 1\n","when input is [45, 44, 55, 55, 6, 4, 0, 1] the target: 1\n","when input is [56] the target: 44\n","when input is [56, 44] the target: 50\n","when input is [56, 44, 50] the target: 48\n","when input is [56, 44, 50, 48] the target: 1\n","when input is [56, 44, 50, 48, 1] the target: 58\n","when input is [56, 44, 50, 48, 1, 58] the target: 49\n","when input is [56, 44, 50, 48, 1, 58, 49] the target: 1\n","when input is [56, 44, 50, 48, 1, 58, 49, 1] the target: 63\n"]}]},{"cell_type":"code","source":["print(xb) # our input to the transformer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpyyAeIzQjlO","executionInfo":{"status":"ok","timestamp":1723862850962,"user_tz":180,"elapsed":256,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"c300f3dc-74c5-45ba-b800-d66e39e060eb"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1,  1,  1, 20, 51, 44, 61, 56],\n","        [63, 51,  1, 56, 58, 61, 48,  1],\n","        [45, 44, 55, 55,  6,  4,  0,  1],\n","        [56, 44, 50, 48,  1, 58, 49,  1]])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","torch.manual_seed(1337)\n","\n","class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","\n","        logits = self.token_embedding_table(idx)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","\n","        for _ in range(max_new_tokens):\n","            logits, loss = self(idx)\n","            logits = logits[:, -1, :]\n","            probs = F.softmax(logits, dim=-1)\n","            idx_next = torch.multinomial(probs, num_samples=1)\n","            idx = torch.cat((idx, idx_next), dim=1)\n","        return idx\n","\n","m = BigramLanguageModel(vocab_size)\n","logits, loss = m(xb, yb)\n","print(logits.shape)\n","print(loss)\n","\n","print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nql_1ER53oCf","executionInfo":{"status":"ok","timestamp":1723862860834,"user_tz":180,"elapsed":269,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"b4a66d53-46ab-440f-bcfa-ee579ea7353e"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 70])\n","tensor(4.8308, grad_fn=<NllLossBackward0>)\n","\n","8YStBOyiPdh5AHbDbbczl\n","GF9A 3ql\n","KtS9,Mpf,BnVVXNaUUfCA4Th5gZSyY\n","ocmJ0fFzl3HUagEIX-oO,rrFIaHMMGIXItaRW3\n"]}]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"],"metadata":{"id":"eTyJ8qAaDdiF","executionInfo":{"status":"ok","timestamp":1723862859217,"user_tz":180,"elapsed":269,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","for steps in range(3000):\n","\n","\n","    xb, yb = get_batch('train')\n","\n","    logits, loss = m(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n","print(loss.item())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hs4kI8YdEkQj","executionInfo":{"status":"ok","timestamp":1723862870508,"user_tz":180,"elapsed":5779,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"58d66e98-3dda-4f30-cfd3-a737c61f4489"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["4.816384315490723\n"]}]},{"cell_type":"code","source":["print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcVIDWAZEtjN","executionInfo":{"status":"ok","timestamp":1723862875056,"user_tz":180,"elapsed":260,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"bdeee01e-efa9-417c-b6e3-c1a6c962b913"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","KySen.1WSQkVeSEGNTEXWXf!12ezmWcVxWP6lY'BfsV HKDCg'QGBiETcOWlrvBWrzy9-cuRNWlR23KW2 ItPpw-7ccbl7W-5JMwl-'zldGCG5cpjh!mgd-:XnnA4zK-t0AwxXkDtvmkedCqQczYjlWMPYJ1zg',TMogeTJ:xTbOM9-cS:x6jM2R6tySS:CYDIxHTh!W37RibhE74JQ35LqFueAyZn q,EjlOxRJ\n","jz VhK g'N,:8N sIt:7ObObFtxWXD97zlQynr'Y,cPbLdAMoWlzmetr87.6NPWl\n","T'g'YNf,WQNVVS1RLRpF,Qh4szv21m.mLNas98HiY\n","KU\n","NasT\n","rgBom8aIdR,9g69-7ldBfbvavXl,Gc3h1beE1bw38ngiRQ'98ZycLxHlP3UoAw9k!bNTMOa\n","qiYmfss475m6GcVG\n","E88YcK1gmW-x8FzXi,mwK\n","N aU9K1ko.:awD0YWle-RN97y0Y,6dVk9FAHLBX1z\n"]}]},{"cell_type":"code","source":["\n","torch.manual_seed(42)\n","a = torch.tril(torch.ones(3, 3))\n","a = a / torch.sum(a, 1, keepdim=True)\n","b = torch.randint(0,10,(3,2)).float()\n","c = a @ b\n","print('a=')\n","print(a)\n","print('--')\n","print('b=')\n","print(b)\n","print('--')\n","print('c=')\n","print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tukiH-NbRBhA","executionInfo":{"status":"ok","timestamp":1723860305140,"user_tz":180,"elapsed":302,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"593d88d3-9770-4757-c71d-e09fb306afb0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["a=\n","tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]])\n","--\n","b=\n","tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","--\n","c=\n","tensor([[2.0000, 7.0000],\n","        [4.0000, 5.5000],\n","        [4.6667, 5.3333]])\n"]}]},{"cell_type":"code","source":["\n","\n","torch.manual_seed(1337)\n","B,T,C = 4,8,2\n","x = torch.randn(B,T,C)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hs_E24uRE8kr","executionInfo":{"status":"ok","timestamp":1723860310519,"user_tz":180,"elapsed":245,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"f531e8dd-1e31-42d9-e037-b22ee682f59c"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 2])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["\n","xbow = torch.zeros((B,T,C))\n","for b in range(B):\n","    for t in range(T):\n","        xprev = x[b,:t+1]\n","        xbow[b,t] = torch.mean(xprev, 0)\n"],"metadata":{"id":"86NuXX0fn7ps","executionInfo":{"status":"ok","timestamp":1723860319407,"user_tz":180,"elapsed":286,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["\n","wei = torch.tril(torch.ones(T, T))\n","wei = wei / wei.sum(1, keepdim=True)\n","xbow2 = wei @ x\n","torch.allclose(xbow, xbow2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhdOAd6-wXkZ","executionInfo":{"status":"ok","timestamp":1723860324375,"user_tz":180,"elapsed":414,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"4ab28e88-0432-4cac-84b4-631f28efd8bf"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# version 3: use Softmax\n","tril = torch.tril(torch.ones(T, T))\n","wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","xbow3 = wei @ x\n","torch.allclose(xbow, xbow3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOURrfG-ysoL","executionInfo":{"status":"ok","timestamp":1723860620141,"user_tz":180,"elapsed":279,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"f1379e35-77f2-4929-83b0-b98fc756e71f"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["\n","torch.manual_seed(1337)\n","B,T,C = 4,8,32\n","x = torch.randn(B,T,C)\n","\n","head_size = 16\n","key = nn.Linear(C, head_size, bias=False)\n","query = nn.Linear(C, head_size, bias=False)\n","value = nn.Linear(C, head_size, bias=False)\n","k = key(x)\n","q = query(x)\n","wei =  q @ k.transpose(-2, -1)\n","\n","tril = torch.tril(torch.ones(T, T))\n","\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","\n","v = value(x)\n","out = wei @ v\n","\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDarxEWIRMKq","executionInfo":{"status":"ok","timestamp":1723860624026,"user_tz":180,"elapsed":282,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"6ac2b6f4-cf17-4278-a842-8cf4e8274141"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 16])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["wei[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT1hdtzXCjgL","executionInfo":{"status":"ok","timestamp":1673919663417,"user_tz":480,"elapsed":158,"user":{"displayName":"Andrej Karpathy","userId":"01076536098485696680"}},"outputId":"6d2c569b-7922-451f-9934-0fc564678d17"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n","        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n","        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n","        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["k = torch.randn(B,T,head_size)\n","q = torch.randn(B,T,head_size)\n","wei = q @ k.transpose(-2, -1) * head_size**-0.5"],"metadata":{"id":"4SNbLq5z3oBw","executionInfo":{"status":"ok","timestamp":1723860652535,"user_tz":180,"elapsed":265,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["k.var()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nl6I9n9IRTSo","executionInfo":{"status":"ok","timestamp":1723860659081,"user_tz":180,"elapsed":259,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"c683db85-5a10-45f8-c4f3-8eab38615e70"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.0449)"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["q.var()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1tQx7oeRvtc","executionInfo":{"status":"ok","timestamp":1723860660289,"user_tz":180,"elapsed":1,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"bb08fd34-608b-4c87-f878-2c8389d2cf5f"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.0700)"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["wei.var()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLb_odHU3iKM","executionInfo":{"status":"ok","timestamp":1723860661313,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"d0f254e7-b438-4d85-c2a0-8a6e4f424a8b"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.0918)"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JB82yzt44REI","executionInfo":{"status":"ok","timestamp":1723860662455,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"8e375528-b228-4ba7-e76e-87c1c544a0f5"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mpt8569BB9_f","executionInfo":{"status":"ok","timestamp":1723860663165,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"5abbbc37-7b51-44f0-9d32-327d8666e88c"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["class LayerNorm1d:\n","\n","  def __init__(self, dim, eps=1e-5, momentum=0.1):\n","    self.eps = eps\n","    self.gamma = torch.ones(dim)\n","    self.beta = torch.zeros(dim)\n","\n","  def __call__(self, x):\n","\n","    xmean = x.mean(1, keepdim=True)\n","    xvar = x.var(1, keepdim=True)\n","    xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n","    self.out = self.gamma * xhat + self.beta\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.gamma, self.beta]\n","\n","torch.manual_seed(1337)\n","module = LayerNorm1d(100)\n","x = torch.randn(32, 100)\n","x = module(x)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Num7sX9CKOH","executionInfo":{"status":"ok","timestamp":1723860666234,"user_tz":180,"elapsed":299,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"11d9ff9d-a56b-4456-d384-2a490cd9fa9d"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 100])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["x[:,0].mean(), x[:,0].std()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"633T2cmnW1uk","executionInfo":{"status":"ok","timestamp":1723860670120,"user_tz":180,"elapsed":281,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"01c54aed-2ace-4340-ff90-e1dab0b70194"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.1469), tensor(0.8803))"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["x[0,:].mean(), x[0,:].std()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LN9cK9BoXCYb","executionInfo":{"status":"ok","timestamp":1723860671280,"user_tz":180,"elapsed":3,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"96f60ae0-e90b-46fc-9bb3-3c9894b6a63c"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-9.5367e-09), tensor(1.0000))"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","batch_size = 16\n","block_size = 32\n","max_iters = 5000\n","eval_interval = 100\n","learning_rate = 1e-3\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 200\n","n_embd = 64\n","n_head = 4\n","n_layer = 4\n","dropout = 0.0\n","# ------------\n","\n","torch.manual_seed(1337)\n","\n","# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","with open('input.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s]\n","decode = lambda l: ''.join([itos[i] for i in l])\n","\n","data = torch.tensor(encode(text), dtype=torch.long)\n","n = int(0.9*len(data))\n","train_data = data[:n]\n","val_data = data[n:]\n","\n","\n","def get_batch(split):\n","\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    x, y = x.to(device), y.to(device)\n","    return x, y\n","\n","@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False)\n","        self.query = nn.Linear(n_embd, head_size, bias=False)\n","        self.value = nn.Linear(n_embd, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x)\n","        q = self.query(x)\n","        wei = q @ k.transpose(-2,-1) * C**-0.5\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","        wei = F.softmax(wei, dim=-1)\n","        wei = self.dropout(wei)\n","        v = self.value(x)\n","        out = wei @ v\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(n_embd, n_embd)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.dropout(self.proj(out))\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","\n","class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm(n_embd)\n","        self.lm_head = nn.Linear(n_embd, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","\n","        tok_emb = self.token_embedding_table(idx)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n","        x = tok_emb + pos_emb\n","        x = self.blocks(x)\n","        x = self.ln_f(x)\n","        logits = self.lm_head(x)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        for _ in range(max_new_tokens):\n","            idx_cond = idx[:, -block_size:]\n","            logits, loss = self(idx_cond)\n","            logits = logits[:, -1, :]\n","            probs = F.softmax(logits, dim=-1)\n","            idx_next = torch.multinomial(probs, num_samples=1)\n","            idx = torch.cat((idx, idx_next), dim=1)\n","        return idx\n","\n","model = BigramLanguageModel()\n","m = model.to(device)\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","for iter in range(max_iters):\n","\n","    if iter % eval_interval == 0 or iter == max_iters - 1:\n","        losses = estimate_loss()\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    xb, yb = get_batch('train')\n","\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n","context = torch.zeros((1, 1), dtype=torch.long, device=device)\n","print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hoelkOrFY8bN","executionInfo":{"status":"ok","timestamp":1723861258144,"user_tz":180,"elapsed":570798,"user":{"displayName":"Luiz Felipe","userId":"17211877351204909310"}},"outputId":"75887c3a-b8ea-4870-e1c3-f6024b62f68a"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["0.209729 M parameters\n","step 0: train loss 4.4116, val loss 4.4022\n","step 100: train loss 2.6568, val loss 2.6670\n","step 200: train loss 2.5090, val loss 2.5059\n","step 300: train loss 2.4196, val loss 2.4338\n","step 400: train loss 2.3504, val loss 2.3566\n","step 500: train loss 2.2965, val loss 2.3129\n","step 600: train loss 2.2410, val loss 2.2500\n","step 700: train loss 2.2057, val loss 2.2191\n","step 800: train loss 2.1633, val loss 2.1864\n","step 900: train loss 2.1244, val loss 2.1510\n","step 1000: train loss 2.1038, val loss 2.1308\n","step 1100: train loss 2.0707, val loss 2.1197\n","step 1200: train loss 2.0377, val loss 2.0800\n","step 1300: train loss 2.0268, val loss 2.0650\n","step 1400: train loss 1.9918, val loss 2.0356\n","step 1500: train loss 1.9697, val loss 2.0293\n","step 1600: train loss 1.9645, val loss 2.0499\n","step 1700: train loss 1.9404, val loss 2.0129\n","step 1800: train loss 1.9095, val loss 1.9951\n","step 1900: train loss 1.9067, val loss 1.9855\n","step 2000: train loss 1.8854, val loss 1.9948\n","step 2100: train loss 1.8727, val loss 1.9766\n","step 2200: train loss 1.8597, val loss 1.9631\n","step 2300: train loss 1.8530, val loss 1.9516\n","step 2400: train loss 1.8428, val loss 1.9464\n","step 2500: train loss 1.8161, val loss 1.9424\n","step 2600: train loss 1.8283, val loss 1.9406\n","step 2700: train loss 1.8101, val loss 1.9322\n","step 2800: train loss 1.8050, val loss 1.9233\n","step 2900: train loss 1.8033, val loss 1.9289\n","step 3000: train loss 1.7955, val loss 1.9216\n","step 3100: train loss 1.7697, val loss 1.9184\n","step 3200: train loss 1.7541, val loss 1.9088\n","step 3300: train loss 1.7567, val loss 1.9034\n","step 3400: train loss 1.7573, val loss 1.9000\n","step 3500: train loss 1.7398, val loss 1.8925\n","step 3600: train loss 1.7270, val loss 1.8869\n","step 3700: train loss 1.7283, val loss 1.8814\n","step 3800: train loss 1.7210, val loss 1.8918\n","step 3900: train loss 1.7219, val loss 1.8732\n","step 4000: train loss 1.7146, val loss 1.8576\n","step 4100: train loss 1.7136, val loss 1.8720\n","step 4200: train loss 1.7060, val loss 1.8653\n","step 4300: train loss 1.7032, val loss 1.8499\n","step 4400: train loss 1.7057, val loss 1.8656\n","step 4500: train loss 1.6907, val loss 1.8477\n","step 4600: train loss 1.6878, val loss 1.8371\n","step 4700: train loss 1.6808, val loss 1.8415\n","step 4800: train loss 1.6689, val loss 1.8457\n","step 4900: train loss 1.6716, val loss 1.8415\n","step 4999: train loss 1.6658, val loss 1.8275\n","\n","ROTCUMER:\n","Tyburforth, bloody,\n","WhIs migute: you duke I use list. WIthon of where's grande will! savist tought!\n","Why room upwor alond, liegle. I hone, Iell thou sudd have then strue thus mind,\n","His by blow, Virdom tow, glingien, yithre spees ssince them Those not.\n","\n","LUCIO:\n","Look,----\n","But thou sging them this my freceimmsed,\n","By thou sovor conursion that thou sade but grove\n","the tage encond:\n","It will Rament me; an your touther,\n","And havis like to-does, and little spright.\n","\n","GLOUCESTER:\n","Rewards thou for Panfessira's bigguards such ways!\n","What curfort his\n","will havolss you, as I have the cervirs arled,\n","Dear my love and pitace unto duly son.\n","\n","Secome:\n","Offolk, even thy whose my late all that you by jotly us belies!\n","Lord, we a-montencry! I\n","\n","SLARNE:\n","Day, mave from out prrive And orculing\n","What confess, temimelyour and stropt;\n","Secumfospet the gatieus I'll that confence-sting,\n","But; man't, Rolget\n","would garnion'd live in which, you, prothre?\n","\n","CORIOLANUS:\n","What bonum stravoing, not out be seemmed with\n","That the boly noll to.\n","Bently, which in on my not tomberven why, fortune,\n","And that wark you, banot thus orl'ld groves viles.\n","\n","PUMNIUS:\n","It thou addow less, proth-straing.\n","Mutwing your contrant stomfe, whom they\n","is by this famestle; and of the loves my not Mercarcious to the stord; thesoo, in thus my nome are:\n","Will fuch, have there enplience your gone, ho's,\n","And gentleman, my beged lind to be am\n","in That ant:\n","In I sugner murded! I play's,\n","If not sume the confity will reasur slord:\n","That get because at that his say\n","and to beepts guarst you lom if then.\n","\n","MENEN MARGARUS:\n","I but aftelence! made yoour never.\n","\n","KING RICHARD II:\n","Who too near?\n","\n","LORDIUS:\n","Or as madaw brird, tou thee?\n","\n","Sirightly the haste's beforempt.\n","\n","First:\n","Is though.\n","Fell, whose toes with requmpts, up I make\n","Here figUS verean that I will, by the wateon.\n","\n","MOWIDIUS:\n","How, while, more is in meep.\n","twan be the fless this countrens platcar merperter sure make Giventled,\n","At not your must to reason togs,\n","And what you gue;--\n","\n","RUKE ESFiren; gravent,\n","Apol\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fjjvMifYZf7x"},"execution_count":null,"outputs":[]}]}